{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "## Imports\n",
    "\n",
    "- csv: Allow us to interact with the file format we're using for storing data\n",
    "- os: Access the file system for creating folders\n",
    "- random: To shuffle the players on each team for our last algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping our Datasets\n",
    "\n",
    "At the the of writing, around 11.5K data is available to train on. This data is good on it's own, but it can also be split into different batches based on our intervals. Additionally, we should remove the first line, since that line is only useful to our data grabbing algorithm, and not useful for our analysis.\n",
    "\n",
    "### Main Batches\n",
    "\n",
    "Lets use a folder to easily store all of our batches of data. First, we need to create that folder if it doesn't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found .\\batches\n"
     ]
    }
   ],
   "source": [
    "BATCH_DIRNAME = 'batches'\n",
    "if not os.path.exists(BATCH_DIRNAME):\n",
    "    print(rf\"Path .\\{BATCH_DIRNAME} not found!\")\n",
    "    os.makedirs(BATCH_DIRNAME)\n",
    "    print(\"Directory created!\")\n",
    "else:\n",
    "    print(rf\"Found .\\{BATCH_DIRNAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, before we start trying to make more batches, let's make a utility function that will separate our batch based on whatever parameters we provide. We can pass in an input and output file name to use, and a function to use for comparing and modifying data. Additionally, lets always skip the first line, which does not contain relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(input_batch: str, output_batch: str, operator, skip_first: bool = False) -> None:\n",
    "    with open(input_batch, 'r', encoding='utf-8', newline='') as infile, \\\n",
    "            open(output_batch, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        \n",
    "        if skip_first:\n",
    "            infile.readline()   # discard the first line if we're reading from our main collected data.\n",
    "\n",
    "        reader = csv.reader(infile, quoting=csv.QUOTE_MINIMAL, doublequote=False, escapechar='\\\\')\n",
    "        writer = csv.writer(outfile, quoting=csv.QUOTE_MINIMAL, doublequote=False, escapechar='\\\\')\n",
    "        for line in reader:\n",
    "            data = operator(line)\n",
    "            if data:\n",
    "                writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily create our batches just by specifying a batch function. This function will be given a list of data on a line, stored in strings, and should output the data that should be written in the output, or nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTED_DATA_FILENAME = 'sendouq-data.csv'\n",
    "\n",
    "make_batch(COLLECTED_DATA_FILENAME, f'{BATCH_DIRNAME}\\\\empty.csv', lambda x : None, True)\n",
    "make_batch(COLLECTED_DATA_FILENAME, f'{BATCH_DIRNAME}\\\\all.csv', lambda x : x, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we're easily able to make batches of our data by just providing a simple anonymous function.\n",
    "\n",
    "### Batching by Date\n",
    "\n",
    "When collecting our data, we gathered data from separate intervals in season 1, 2, and 3. We can make batches for each of these seasons.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate the match_ID values for the start of each interval\n",
    "SEASON_2_START = 23027\n",
    "SEASON_3_START = 37626\n",
    "\n",
    "make_batch(f'{BATCH_DIRNAME}\\\\all.csv', f'{BATCH_DIRNAME}\\\\season_1.csv',\n",
    "           lambda x : x if int(x[0]) < SEASON_2_START else None)\n",
    "make_batch(f'{BATCH_DIRNAME}\\\\all.csv', f'{BATCH_DIRNAME}\\\\season_2.csv',\n",
    "           lambda x : x if SEASON_2_START <= int(x[0]) < SEASON_3_START else None)\n",
    "make_batch(f'{BATCH_DIRNAME}\\\\all.csv', f'{BATCH_DIRNAME}\\\\season_3.csv',\n",
    "           lambda x : x if SEASON_3_START <= int(x[0]) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Players\n",
    "\n",
    "Finally, we could add a preprocessing step to see if that results in any significant change to our results. In this step, instead of filtering as before, this will transform the data. This step will result in the players on the same team to be sorted by rating. This doesn't actually change anything significant about our data, since the order of each player on a team does not change. Which players were on Alpha and Bravo will not be changed by this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_players(data: list[str]) -> list[str | int]:\n",
    "    alpha = []\n",
    "    # 1-4 is team alpha (0 is match_id)\n",
    "    for i in range(1, 5):\n",
    "        alpha.append(float(data[i]))\n",
    "    \n",
    "    bravo = []\n",
    "    # 5-8 is team bravo (9 is result)\n",
    "    for i in range(5, 9):\n",
    "        bravo.append(float(data[i]))\n",
    "    \n",
    "    # sort alpha and bravo teams\n",
    "    alpha.sort()\n",
    "    bravo.sort()\n",
    "\n",
    "    # make our new data entry\n",
    "    return [data[0]] + alpha + bravo + [data[9]]\n",
    "\n",
    "batches_to_sort = ['all', 'season_1', 'season_2', 'season_3']\n",
    "for batch in batches_to_sort:\n",
    "    make_batch(f'{BATCH_DIRNAME}\\\\{batch}.csv',\n",
    "               f'{BATCH_DIRNAME}\\\\{batch}_sorted.csv', sort_players)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Bravo Bias\n",
    "\n",
    "Analyzing our data, we find that there's a significant bias towards the bravo team in the data. Go read the beginning of ml-analysis and come back here. The players on alpha or bravo should not affect the outcome of the predictions, therefore we should try to remove this bias if possible.\n",
    "\n",
    "The first strategy I will use is mirroring every data point so that alpha and bravo wins are 50/50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as make batch but use writerows instead of writerow\n",
    "def make_batch_multi(input_batch: str, output_batch: str, operator, skip_first: bool = False) -> None:\n",
    "    with open(input_batch, 'r', encoding='utf-8', newline='') as infile, \\\n",
    "            open(output_batch, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        \n",
    "        if skip_first:\n",
    "            infile.readline()   # discard the first line if we're reading from our main collected data.\n",
    "\n",
    "        reader = csv.reader(infile, quoting=csv.QUOTE_MINIMAL, doublequote=False, escapechar='\\\\')\n",
    "        writer = csv.writer(outfile, quoting=csv.QUOTE_MINIMAL, doublequote=False, escapechar='\\\\')\n",
    "        for line in reader:\n",
    "            data = operator(line)\n",
    "            if data:\n",
    "                writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_matches(data: list[str]) -> list[list[str]]:\n",
    "    out = [data]\n",
    "    alpha = data[1:5]\n",
    "    bravo = data[5:9]\n",
    "    winner = [1 - int(data[9])]\n",
    "    mirror = [data[0]] + bravo + alpha + winner\n",
    "    out.append(mirror)\n",
    "    return out\n",
    "\n",
    "batches_to_mirror = ['all', 'season_1', 'season_2', 'season_3']\n",
    "for batch in batches_to_mirror:\n",
    "    make_batch_multi(f'{BATCH_DIRNAME}\\\\{batch}.csv',\n",
    "                     f'{BATCH_DIRNAME}\\\\{batch}_mirrored.csv', mirror_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Player Slot Bias\n",
    "\n",
    "This still isn't enough to reduce the bias. See even further in ml-analysis. But to put it briefly, the slot each player ends up in shouldn't affect the outcome of the data. For example, if both teams have 3 1500s and a 2000 player, they should have an equal change of winning no matter which slot the 2000s end up in. There's two ways we could fix this. We could add another line of data for every combination of players in the match. With both every combination of players and mirroring each match, we would have to multiply our data by $4!*4!*2=1152$. This is way too many lines to add per data point.\n",
    "\n",
    "Instead, we can use a fair randomization to random the players on each team. Then, we can mirror like usual to reduce bravo bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mirror(data: list[str]) -> list[list[str]]:\n",
    "    alpha = data[1:5]\n",
    "    bravo = data[5:9]\n",
    "\n",
    "    random.shuffle(alpha)\n",
    "    random.shuffle(bravo)\n",
    "\n",
    "    winner = int(data[9])\n",
    "\n",
    "    out = []\n",
    "    original = [data[0]] + alpha + bravo + [winner]\n",
    "    mirror = [data[0]] + bravo + alpha + [1-winner]\n",
    "    out.append(original)\n",
    "    out.append(mirror)\n",
    "    return out\n",
    "\n",
    "batches_to_mirror = ['all', 'season_1', 'season_2', 'season_3']\n",
    "for batch in batches_to_mirror:\n",
    "    make_batch_multi(f'{BATCH_DIRNAME}\\\\{batch}.csv',\n",
    "                     f'{BATCH_DIRNAME}\\\\{batch}_rmirrored.csv', random_mirror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is decent, but the bias still exists. Lets try again, by not only randomizing and mirroring each match, but duplicating the data a few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_random_mirror(k: int) -> list[list[str]]:\n",
    "    def func(data: list[str]):\n",
    "        alpha = data[1:5]\n",
    "        bravo = data[5:9]\n",
    "\n",
    "        winner = int(data[9])\n",
    "\n",
    "        out = []\n",
    "        for i in range(k):\n",
    "            random.shuffle(alpha)\n",
    "            random.shuffle(bravo)\n",
    "\n",
    "            original = [data[0]] + alpha + bravo + [winner]\n",
    "            mirror = [data[0]] + bravo + alpha + [1-winner]\n",
    "            out.append(original)\n",
    "            out.append(mirror)\n",
    "        return out\n",
    "    return func\n",
    "\n",
    "batches_to_mirror = ['all', 'season_1', 'season_2', 'season_3']\n",
    "for batch in batches_to_mirror:\n",
    "    make_batch_multi(f'{BATCH_DIRNAME}\\\\{batch}.csv',\n",
    "                     f'{BATCH_DIRNAME}\\\\{batch}_k5.csv', k_random_mirror(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
