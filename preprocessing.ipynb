{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "## Imports\n",
    "\n",
    "- csv: Allow us to interact with the file format we're using for storing data\n",
    "- os: Access the file system for creating folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping our Datasets\n",
    "\n",
    "At the the of writing, around 11.5K data is available to train on. This data is good on it's own, but it can also be split into different batches based on our intervals. Additionally, we should remove the first line, since that line is only useful to our data grabbing algorithm, and not useful for our analysis.\n",
    "\n",
    "### Main Batches\n",
    "\n",
    "Lets use a folder to easily store all of our batches of data. First, we need to create that folder if it doesn't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found .\\batches\n"
     ]
    }
   ],
   "source": [
    "BATCH_DIRNAME = 'batches'\n",
    "if not os.path.exists(BATCH_DIRNAME):\n",
    "    print(rf\"Path .\\{BATCH_DIRNAME} not found!\")\n",
    "    os.makedirs(BATCH_DIRNAME)\n",
    "    print(\"Directory created!\")\n",
    "else:\n",
    "    print(rf\"Found .\\{BATCH_DIRNAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, before we start trying to make more batches, let's make a utility function that will separate our batch based on whatever parameters we provide. We can pass in an input and output file name to use, and a function to use for comparing and modifying data. Additionally, lets always skip the first line, which does not contain relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(input_batch: str, output_batch: str, operator, skip_first: bool = False) -> None:\n",
    "    with open(input_batch, 'r', encoding='utf-8', newline='') as infile, \\\n",
    "            open(output_batch, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        \n",
    "        if skip_first:\n",
    "            infile.readline()   # discard the first line if we're reading from our main collected data.\n",
    "\n",
    "        reader = csv.reader(infile, quoting=csv.QUOTE_MINIMAL, doublequote=False, escapechar='\\\\')\n",
    "        writer = csv.writer(outfile, quoting=csv.QUOTE_MINIMAL, doublequote=False, escapechar='\\\\')\n",
    "        for line in reader:\n",
    "            data = operator(line)\n",
    "            if data:\n",
    "                writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily create our batches just by specifying a batch function. This function will be given a list of data on a line, stored in strings, and should output the data that should be written in the output, or nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTED_DATA_FILENAME = 'sendouq-data.csv'\n",
    "\n",
    "make_batch(COLLECTED_DATA_FILENAME, f'{BATCH_DIRNAME}\\\\empty.csv', lambda x : None, True)\n",
    "make_batch(COLLECTED_DATA_FILENAME, f'{BATCH_DIRNAME}\\\\all.csv', lambda x : x, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we're easily able to make batches of our data by just providing a simple anonymous function.\n",
    "\n",
    "### Batching by Date\n",
    "\n",
    "When collecting our data, we gathered data from separate intervals in season 1, 2, and 3. We can make batches for each of these seasons.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate the match_ID values for the start of each interval\n",
    "SEASON_2_START = 23027\n",
    "SEASON_3_START = 37626\n",
    "\n",
    "make_batch(f'{BATCH_DIRNAME}\\\\all.csv', f'{BATCH_DIRNAME}\\\\season_1.csv',\n",
    "           lambda x : x if int(x[0]) < SEASON_2_START else None)\n",
    "make_batch(f'{BATCH_DIRNAME}\\\\all.csv', f'{BATCH_DIRNAME}\\\\season_2.csv',\n",
    "           lambda x : x if SEASON_2_START <= int(x[0]) < SEASON_3_START else None)\n",
    "make_batch(f'{BATCH_DIRNAME}\\\\all.csv', f'{BATCH_DIRNAME}\\\\season_3.csv',\n",
    "           lambda x : x if SEASON_3_START <= int(x[0]) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Players\n",
    "\n",
    "Finally, we could add a preprocessing step to see if that results in any significant change to our results. In this step, instead of filtering as before, this will transform the data. This step will result in the players on the same team to be sorted by rating. This doesn't actually change anything significant about our data, since the order of each player on a team does not change. Which players were on Alpha and Bravo will not be changed by this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_players(data: list[str]) -> list[str | int]:\n",
    "    alpha = []\n",
    "    # 1-4 is team alpha (0 is match_id)\n",
    "    for i in range(1, 5):\n",
    "        alpha.append(float(data[i]))\n",
    "    \n",
    "    bravo = []\n",
    "    # 5-8 is team bravo (9 is result)\n",
    "    for i in range(5, 9):\n",
    "        bravo.append(float(data[i]))\n",
    "    \n",
    "    # sort alpha and bravo teams\n",
    "    alpha.sort()\n",
    "    bravo.sort()\n",
    "\n",
    "    # make our new data entry\n",
    "    return [data[0]] + alpha + bravo + [data[9]]\n",
    "\n",
    "batches_to_sort = ['all', 'season_1', 'season_2', 'season_3']\n",
    "for batch in batches_to_sort:\n",
    "    make_batch(f'{BATCH_DIRNAME}\\\\{batch}.csv',\n",
    "               f'{BATCH_DIRNAME}\\\\{batch}_sorted.csv', sort_players)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
